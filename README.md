# ğŸ§  AI Co-Workspace

**Claude-style AI co-workspace built for engineers.**
Persistent memory, artifact intelligence, transparent RAG, and multi-model LLM orchestration â€” designed for real project workflows, not just chat.

---

## âœ¨ Overview

AI Co-Workspace is an **open-source, workspace-centric AI platform** where conversations evolve into artifacts, artifacts become memory, and memory actively informs future reasoning.

Unlike traditional AI chat tools, this system treats **context as infrastructure** â€” observable, editable, and extensible.

Think **Claude Workspaces**, but:

* Open-source
* Multi-model
* Local-first
* RAG-transparent
* Engineer-controlled

---

## ğŸ¯ Why This Project Exists

Modern LLM tools are powerful, but they:

* Forget long-running projects
* Hide how memory and context are selected
* Lock users into a single model
* Treat artifacts as disposable outputs
* Offer no observability or control

**AI Co-Workspace explores what an AI system looks like when memory, artifacts, and context are first-class, inspectable systems.**

---

## ğŸš€ Core Capabilities

### ğŸ—‚ï¸ Workspace-First Design

Each workspace is fully isolated and owns:

* Chats
* Artifacts
* Files
* Memory
* Context rules

No cross-project contamination. No global memory leaks.

---

### ğŸ’¬ Intelligent Chat System

* Workspace-scoped chat sessions
* Message history with summarization
* Streaming-ready API design
* Built for long-running collaboration

---

### ğŸ§  Persistent Memory (RAG-Powered)

Memory is not magic â€” itâ€™s **explicit and inspectable**.

Memory sources:

* Chat summaries
* Artifacts (code, docs, configs)
* Uploaded files

Retrieval:

* Keyword + semantic search
* Vector DB backed (Chroma / Qdrant)
* Workspace-scoped context injection

---

### ğŸ“„ Artifact Intelligence

Artifacts are not just displayed â€” they are **understood**.

* Automatic artifact detection
* Artifact lifecycle:

  * Detect â†’ Create â†’ Update â†’ Persist
* Artifacts feed memory and future reasoning
* Workspace-aware artifact management

---

### ğŸ”Œ Multi-Model LLM Support

Model-agnostic by design.

Supported:

* Ollama (local LLMs)
* OpenAI
* Extensible model registry

Switch models per workspace or task â€” no lock-in.

---

### ğŸ“Š Observability (Planned)

Designed for engineers who care about internals:

* Context inspection
* Retrieved memory visibility
* Token usage tracking
* Cost awareness

---

## ğŸ†š What This Has That Claude Workspaces Donâ€™t

| Capability          | Claude | AI Co-Workspace |
| ------------------- | ------ | --------------- |
| Editable memory     | âŒ      | âœ…               |
| Transparent RAG     | âŒ      | âœ…               |
| Artifact lifecycle  | âŒ      | âœ…               |
| Multi-model support | âŒ      | âœ…               |
| Local LLMs          | âŒ      | âœ…               |
| Workspace export    | âŒ      | âœ…               |
| Extensible APIs     | âŒ      | âœ…               |

> Claude is a closed product.
> AI Co-Workspace is an **open platform**.

---

## ğŸ—ï¸ Architecture Flow

```
User Prompt
   â†“
Workspace Context Builder
   â†“
Memory Retrieval (RAG)
   â†“
Prompt Builder
   â†“
LLM (Ollama / OpenAI)
   â†“
Response
   â†“
Artifact Detection
   â†“
Memory Update
```

---

## ğŸ“ Repository Structure

```
ai-co-workspace/
â”œâ”€â”€ backend/            # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/        # REST APIs
â”‚   â”‚   â”œâ”€â”€ services/   # LLM, memory, RAG, artifacts
â”‚   â”‚   â”œâ”€â”€ db/         # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ core/       # Config, security, lifecycle
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ frontend/           # Next.js workspace UI
â”‚
â”œâ”€â”€ vectorstore/        # Chroma / Qdrant persistence
â”‚
â”œâ”€â”€ infra/              # Docker, Kubernetes, Terraform
â”‚
â”œâ”€â”€ docs/               # Architecture & design docs
â”‚
â””â”€â”€ scripts/            # Dev utilities & migrations
```

See `/docs` for deep dives into architecture, memory systems, and artifact lifecycle.

---

## ğŸ› ï¸ Tech Stack

### Backend

* FastAPI
* SQLAlchemy
* Async service architecture
* Modular domain design

### LLMs

* Ollama (local-first)
* OpenAI
* Model registry abstraction

### Memory & RAG

* Chroma / Qdrant
* Embedding abstraction
* Semantic + keyword retrieval

### Frontend

* Next.js
* TailwindCSS
* Workspace-centric UI

### Infrastructure

* Docker & Docker Compose
* Kubernetes manifests
* Terraform modules

---

## ğŸ§ª What This Project Is NOT

* âŒ Not an LLM training platform
* âŒ Not a fine-tuning pipeline
* âŒ Not a Claude UI clone
* âŒ Not tied to one vendor or cloud

This project focuses on **LLM orchestration, memory systems, and workspace intelligence**.

---

## ğŸ—ºï¸ MVP Execution Phases

1ï¸âƒ£ Backend workspace & chat APIs
2ï¸âƒ£ Ollama LLM integration
3ï¸âƒ£ Prompt builder + memory retrieval
4ï¸âƒ£ Artifact detection & lifecycle
5ï¸âƒ£ Frontend workspace UI
6ï¸âƒ£ Vector DB & semantic memory
7ï¸âƒ£ Polishing, observability & docs

---

## ğŸ“¦ Data Ownership & Portability

* Workspace export (JSON / Markdown)
* Local-first execution
* No vendor lock-in
* Your data, your models, your control

---

## ğŸ¤ Who This Is For

* Cloud & DevOps engineers
* AI platform builders
* RAG system designers
* Open-source contributors
* Teams building serious, long-running AI projects

---

## ğŸ“œ License

MIT License â€” build freely, fork openly, ship boldly.

---

## ğŸ§­ Roadmap Highlights

* Memory pinning & importance scoring
* Artifact versioning & diffs
* Context inspection UI
* Plugin & webhook system
* CI/CD & GitHub integrations

---

## â­ Final Note

This project isnâ€™t about replacing Claude.

It answers a different question:

> **â€œWhat does an AI workspace look like when engineers control memory, context, and models?â€**

---
